## 02.05.2020

- cidr: Classless Inter-Domain Routing

  - subnetmask로도 ip 할당 범위를 지정할 수 있지만 그것보다 더 가독성이 좋은 방식이다.
  - 여러 ip가 모인 그룹이라고 할 수 있다.
  - cidr 블락을 여러개의 네트워크로 나누는 것을 subnetting이라고 한다.
  - 각각의 class를 2진수로 바꾸면 8비트 값이 되고, 총 32비트각 된다.
  - cidr값은 32부터 0까지 사용할 수 있다.
  - 유효한 클래스 범위는 0부터 255까지이다.
  - 예를 들어, `171.16.0.0/24`라는 ip가 있다면 `171.16.0`까지는 network prefix가 되고, `0`은 host identifier가 된다. 허용되는 ip의 범위는 `171.16.0.0`부터 `171.16.0.254`까지가 되겠다.

- dev platform for mobile/web app

  - 비슷한 점
    - 스케일링이 되고 안전하게 모바일/웹 애플리케이션을 빌드할 수 있게 디자인된 플랫폼이다.
    - 유저 인증을 간편하게 도와주고, 데이터/사용자 메타데이터를 데이터에 선택적 접근을 허가하고, 머신러닝을 통합시켜준다.
  - 기능
    - 리얼타임 앱
      - 사용자에게 동적으로 데이터를 업데이트하는 것이 필요하다.
      - amplify는 appSync, dynamoDB를 제어할 수 있다.
        - appSync
          - 리얼타임과 더불어 애플리케이션을 손쉽게 스케일업할 수 있도록 도와준다.
          - 디바이스가 오프라인일때 로컬데이터 접근을 제공한다.
          - 디바이스가 다시 온라인이 될때 시스템 충돌을 쉽게 제어하고 동기화시켜준다.
        - dynamoDB는 빠르고 예측가능한 퍼포먼스를 가지고 있으며 스케일링이 손쉽다.
    - 인증
      - cognito와 firebase authentication는 oAuth2.0, Saml2.0, openId 연결 및 sns 로그인을 지원한다.
    - 머신러닝
  - firebase
    - 장점
      - 러닝커브각 낮다.
      - 인증이나 로그인 기능을 추가하는데 걸리는 시간이 짧다.
      - amplify보다 기능이 더 많다.
      - 소/중 사이즈의 프로젝트에 적합한 선택이다.
    - 단점
      - 1m/s 이상의 트랜젝션이 일어나는 빅데이터 프로젝트에는 적합한 선택이 아니다.
  - amplify
    - 장점
      - 다양한 클라우드 기능을 연결해 활용해 애플리케이션의 기능을 개선할 수 있다.
      - graphQl로 데이터 프로세싱을 쉽게 제어할 수 있다.
      - 가격을 저렴하게 조정 가능하다.
    - 단점
      - 러닝커브가 높다.

- push notification

  - 푸시메시지를 송수신하기 위해 사용자기기의 푸시토큰이 필요하다.
  - 보통 신규가입할 때 토큰을 db에 저장한다.
  - 토큰은 아래와 같은 경우에 변경될 수 있으므로 세밀하기 고려해야 한다.
    - firebase의 앱 인스턴스 id가 삭제될때
    - 앱이 새로운 기기에 설치될 **때``**
    - 사용자가 앱을 지우고 다시 설치할 때
    - 사용자가 앱 데이터를 지울 때

- network

  - public/private subnet이 있는 vpc(nat)
    - backend server에 대한 공개적인 접근을 차단하면서 public web app을 실행하려는 시나리오이다.
    - 일반적으로 web server는 public subnet에 두고 db는 private subnet에 두는 다중 계층이 있다.
    - web server가 db와 통신할 수 있도록 보안/라우팅 설정을 할 수 있다.
    - public subnet의 인스턴스는 바로 outbound 트래픽을 전송할 수 있지만, private subnet의 인스턴스는 그렇게 할 수 없고 public에 있는 nat gw를 사용해 접근할 수 있다.
    - nat gw를 이용해 db를 인터넷에 연결할 수 있지만, 인터넷에서 db로 연결을 설정할 수는 없다.
    - vpc 마법사로 nat 인스턴스로 vpc를 구성할 수도 있지만 nat gw를 사용하는 것이 좋다.
    - 구성
      - vpc는 65,536개의 private ip 주소를 제공한다.
      - public subnet은 256개의 private ip 주소를 제공한다. igw로 이어지는 경로가 있는 routing table과 연결된 subnet이다.
      - private subnet은 256개의 private ip 주소를 제공한다.
      - igw는 vpc를 인터넷이나 다른 서비스에 연결한다.
      - subnet 범위에서 private ip 주소가 있는 인스턴스는 인스턴스끼리 서로 통신이 가능하고, vpc의 다른 인스턴스와 통신할 수 있다.
      - 자체적으로 elastic ip 주소를 가진 nat gw를 통해 private subnet의 인스턴스가 인터넷에 요청을 보낼 수가 있다. 예를 들어 소프트웨어 업데이트를 하는 경우가 있을 수 있다.
      - public subnet과 연결된 routing table은 subnet의 인스턴스가 vpc의 다른 인스턴스와 통신할 수 있게 해주며, nat gw를 통해 인터넷과 통신할 수 있게 해준다.
        <img src="https://docs.aws.amazon.com/ko_kr/vpc/latest/userguide/images/nat-gateway-diagram.png" width="500">
    - 라우팅
      - private subnet에 사용되는 기본 routing table을 업데이트하고 public subnet에 연결한다.
      - db는 private subnet에 들어가있으므로 elastic ip가 없어서 직접 인터넷에서 트래픽을 수신할 수가 없어서, public subnet의 nat 디바이스를 통해 인터넷과 통신할 수 있다.
  - 단일 public subnet이 있는 vpc
  - public/private subnet과 site-to-site vpn 접근을 포함하는 vpc
  - private subnet만 있고 site-to-site vpn 접근 권한이 있는 vpc

- github actions
  - workflow를 구축하기 위한 최소 단위의 블럭을 말한다.
  - artifact
    - build와 test를 수행할 때 만들어지는 파일을 말한다.
    - binary, package, test 결과, 스크린샷, 로그 파일 등이 역기 포함된다.
  - event
    - workflow 실행을 유발하는 특정 활동을 말한다.
    - dispatch webhook을 사용해 외부이벤트가 발생할 때 실행되도록 구성할 수도 있다.
  - job
    - 동일한 runner에 의해 수행되는 steps들의 집합을 말한다.
    - build job이 실패하면 test job이 실행되지 않는다.
  - step
    - commands, action을 수행하는 독립적인 작업에 해당한다.
    - 하나의 job은 1개 이상의 step들로 구성된다.
  - workflow
    - 일련의 자동화된 프로세스로 build, test, package, release, deploy 등을 설정할 수 있다.
    - 1개 이상의 job들로 구성되며, 스케쥴링되어 실행되거나 특정 이벤트에 의해 실행되게 할 수 있다.
  - workflow file
    - workflow 설정을 정의하는 yaml파일이다.
    - `./.github/workflows`에 있어야 한다.

## 03.05.2020

- fp
  - functor
    - 보통 값을 품고 있는 어떤 박스 형태로 설명할 수 있다.
    - 값을 안전하게 사용할 수 있도록 도와주는 로직을 가지고 있을 수 있다.
    - 여러 개의 값을 처리할 수 있는 로직을 가지고 있을 수 있다.
    - 아직 값이 결정되지 않았지만 나중에 값이 결정되고나면 값을 사용할 수 있는 로직을 가지고 있을 수 있다.
    - 값을 사용할 때 도움을 주는 여러가지 로직을 담고 있을 수 있다.
    - 조건문에 따라 값을 안전하게 반환하는 어떤 함수도 일종의 박스인 functor라고 할 수 있다.
    - category를 변경하는 행위를 mapping이라고 하며, 카테고리에 함수를 적용해 다른 카테고리로 변경하는 행위라고 할 수도 있다.
    - applicative functor나 monad는 functor로도 해결하지 못하는 예외 상황들까지 커버할 수 있는 더 추상적이고 강력하게 만든 functor락고 할 수 있다.
    - 예시
      ```ts
      interface Functor {
        map(f: (x: T) => U): Functor<U>;
      }
      ```
      - `T` 타입의 값을 가진 functor이다.
      - 콜백을 한 번 돌리면 `U` 타입의 값을 가진 새로운 functor를 얻는다.
      - `map` 메서드는 인자로 받은 함수를 functor 내부의 값에 적용하고, 변경된 값을 감싸고 있는 새로운 functor를 반환한다.
      - `map`에 인자로 넘기는 이 함수가 functor 내부의 값을 변경하는 역할을 실질적으로 하며 transform 함수라고 부른다.
      - 변경된 값을 감싸고 있는 functor가 반환되는 이유는 본질적으로 구조체일 뿐, 카테고리를 부수고 내부의 대상을 꺼내는 역할을 하는게 아니기때문이다.
      - functor는 카테고리를 표현하는 수단일 뿐이라서 기존의 카테고리의 대상을 변경해서는 안된다.
    - 종류
      - `Just`: 내부에 자신의 값을 가지고 있다.
      - `Nothing`: 이름 그대로 내부에 어떠한 값도 가지고 있지 않다.
      - `Maybe`: 값이 있다면 인자로 받은 함수를 값에 적용하고, 값이 없다면 없음을 의미하는 `Nothing` functor를 반환한다.
  - category
    - functor는 카테고리 이론에 등장하는 개념이며, 동일한 구조를 가지고 있는 카테고리들의 관계를 정의할 수 있는 구조체라고 할 수 있다.
- fp

  - functor를 사용해 함수를 합성하기 시작했다면 합성이 끝날 때까지 계속 functor를 사용해야 한다.
  - 애초에 functor를 사용하는 이유는 함수를 합성하는동안 타입 안정성을 유지하고 사이드이펙트를 관리하기 위해서이다.
  - 이 과정에서 functor가 아닌 값이 하나라도 끼어들면 합성한 연산 전체의 안정성을 보장할 수가 없다.
  - 그래서 불변성을 지키면서 배열 내부의 값을 변경하기 위해 무조건 `map` 메서드를 사용해야 한다.
  - `Just`: 원래 가지고 있던 `T` 타입의 값을 `U` 타입의 값으로 변경하고, 이 값을 다시 새로운 `Just` functor에 감싸서 반환하는 것을 의미한다.

    ```ts
    class Just implements Functor {
      value: T;
      constructor(value: T) {
        this.value = value;
      }
      map(f: (x: T) => U) {
        return new Just<U>(f(this.value));
      }
    }

    const res = new Just(3)
      .map((v) => v + 1000)
      .map((v) => v.toString)
      .map((v) => v.length); // Just { value: 4 }
    ```

  - `Nothing`

    ```ts
    class Nothing implements Functor<null> {
      map() {
        return new Nothing();
      }
    }

    const res = new Nothing().map().map(); // Nothing {}
    ```

  - `Maybe`: 중간에 `null`, `undefined`가 반환되어 함수의 합성이 깨지는 걱정 없이 안심하고 합성할 수 있게 도와준다.

    ```ts
    class Maybe implements Functor {
      value: Just | Nothing;
      constructor(value?: T) {
        if (value) {
          this.value = new Just(value);
        } else {
          this.value = new Nothing();
        }
      }
      map(f: (x: T | null) => U) {
        if (this.value instanceof Just) {
          return this.value.map<U>(f);
        } else {
          return new Nothing();
        }
      }
    }

    const getFirstLetter = (s) => s[0];
    const getStringLength = (s) => s.length;

    const foo = new Maybe("hi").map(getFirstLetter).map(getStringLength); // Just { value: 1 }

    const bar = new Maybe("").map(getFirstLetter).map(getStringLength); // Nothing {}
    ```

## 04.05.2020

- collaboration

  - code convention

    - `husky`, `prettier`를 통해 `pre-commit` 시점에 eslint에 정의한 포맷으로 리포맷 하는 것을 추천한다.
    - 컨벤션을 강제하면 최종적으로 원격저장소에서 깔끔한 코드베이스를 유지할 수 있다.
    - ide에 따라 `onSave`에 따라 코드포맷을 재정의할 수도 있지만 다른 개발자가 같은 설정을 해주지 않는다면 흐지부지 끝날 수도 있다.
    - husky가 기존 git hook을 덮어쓰기때문에 설정 전에 저장소를 초기화해야한다.
    - husky가 pre-commit 시점에 해당 확장자를 가진 파일들을 재정의하는 `lint-staged`를 실행한다.

      ```json
      "husky": {
        "hooks": {
          "pre-commit": "lint-staged"
        }
      },

      // example 1
      "lint-staged": {
        "*.{js, ts, json}": [
          "prettier --ignore-path ./.prettierignore --write"
        ]
      }

      // example 2
      "lint-staged": {
        "*.{js, ts}": [
          "npm run lint:eslint:fix",
          "git add --force"
        ],
        "*.json": [
          "prettier --write",
          "git add --force"
        ]
      }
      ```

  - commit message convention
    - `config-conventional`을 통해 커밋로그를 강제할 수가 있다.
      ```sh
      yarn add -D @commitlint/cli @commitlint/config-conventional
      ```
    - 아래와 같은 형태로 커밋을 해야한다.
      ```sh
      <type>[optional scope]: <description>
      # Examples
      feat: add hat wobble
      ^--^  ^------------^
      |     |
      |     +-> Summary in present tense.
      |
      +-------> Type: chore, docs, feat, fix, refactor, style, or test.
      ```
    - 아래와 같이 타입을 사용하면 추후에 릴리즈할 때 자동으로 해당하는 버전이 올라간다.
      - feat(minor): 이용자 단에 새로운 기능 추가 및 하위호환 api 변경
      - fix(patch): 버그 수정 및 api 변경사항 없이 내부 수정
      - breaking(major): api의 큰 변경
      - docs: 문서 추가 및 수정
      - style: 세미콜론 추가 등 포맷 수정
      - refactor: 리팩토링 코드, 변수명 변경
      - test: 테스트 코드 추가 및 수정
      - chore: 그 외 자잘한 수정 사항들
    - 조금 더 자세히 관리하고싶다면 `.commitlintrc.json`으로 관리할 수 있다.
    - husky를 통해 commit-msg 시점에 린트 검사가 가능하다.
  - changelog automation
    - 정규화된 커밋메시지를 토대로 `standard-version`으로 버저닝과 `CHANGELOG.md`를 자동으로 생성할 수 있다.
    - 기본적인 원리는 커밋로그를 뒤져 `package.json`에 새로운 버전을 명시하고 `CHANGELOG.md`에 해당 내용을 추가하는 방식이다.
    - 아래처럼 스크립트를 추가한다.
      ```json
      {
        "scripts": {
          "release": "standard-version"
        }
      }
      ```
  - break point instead of console.log
    - 이를 통해 콜스택과 같은 상세정보를 확인할 수 있기에 순전히 디버깅용으로 `console.log`를 사용하던 사람들에게는 큰 도움이 된다.
    - 코드를 실행할 때 `--inspect` 옵션을 사용해 실행하면 처음부터 디버깅할 때 유용하다.
  - test
    - e2e, 스트레스 테스트는 선택사항이라 하더라도 유닛테스트만은 진행하는 것을 추천한다.
    - tdd와 같은 방법론으로 테스트 케이스 작성을 강제하는 것도 좋다.
    - `jest`를 사용한다면 `converageThreshold`와 같은 옵션으로 커버리지 퍼센티지를 강제해 푸시를 막을 수도 있다.
  - review
    - 코드를 작성한이를 추궁하고 책임을 묻는 시간으로서가 아닌 내용을 점검하고 피드백을 주고받아 잠재적 결함을 찾는 시간이다.
    - 시간이 아깝다고 생각하지 않고 초반에 코드 품질이 좋아지면 장기적으로 생산성이 향상되고 배포속도가 빨라진다.

## 05.05.2020

- fp
  - Either
    - 에러 처리시에 참조할 값을 들고 있는 functor이다.
    - `Left`일 때는 에러 처리에 필요한 값을 가지고, `Right`일 때는 Maybe의 `Just`와 마찬가지로 정상적인 처리를 한다.
    ```ts
    class Either<T> implements Functor<T> {
      value: T;
      constructor(value: T) {
        this.value = value;
      }
      static Left<T>(value: T) {
        return new Left(value);
      }
      static Right<T>(value: T) {
        return new Right(value);
      }
    }
    ```
    - Left
      ```ts
      class Left<T> extends Either<T> {
        get isRight() {
          return false;
        }
        get isLeft() {
          return true;
        }
        map(): any {
          return this;
        }
      }
      ```
    - Right
      ```ts
      class Right<T> extends Either<T> {
        get isRight() {
          return true;
        }
        get isLeft() {
          return false;
        }
        map<U>(f: (x: T) => U) {
          return new Right<U>(f(this.value));
        }
      }
      ```

## 06.05.2020

- ios app distribution

  - 프로젝트를 생성한다.
    - xcode에서 **General - Signing - automatically manage signing**을 해제한다. 이 설정이 체크되어있으면 app id와 인증서, profile이 자동으로 생성되고 설정된 개발자 계정에 등록되버린다.
    - debug/release 모드에 각각 사용할 profile을 등록하는 화면이 나오게 된다.
  - app id를 등록한다.
    - **Identifier - AppIDs**에서 새로운 app id를 추가한다.
    - 프로젝트를 생성할 때 사용했던 bundle id를 적어준다.
    - 등록시 푸시, 인앱 결제 등 필요한 서비스가 있다면 enable시켜준다.
    - app services는 나중에도 수정이 가능하다.
  - 인증서 서명 요청 및 인증서를 생성한다.
    - description
      - 현재는 애플에서 인증받은 개발자가 아니므로 애플에서 인증서를 받아야 하는데, 이를 위해서 맥에서 csr을 생성하고 애플에 제출해야한다.
    - process
      - **Certificates - Development**에서 상황에 맞는 타입을 선택한다.
      - csr(인증서 서명 요청) 파일을 만든다.
      - **KeychainAccess - Certificate Assistant - Request a Certificate From a Certificcate Authority**를 선택한다.
      - 인증정보를 적어준다. 애플 개발자로 등록된 계정을 입력한다. **Request is**는 **Saved to disk**를 선택한다.
      - 이름을 변경하지 않았다면 `CertificateSigningRequest.certSigningRequest` 파일이 생성된다.
      - 개발자 페이지에서 csr 파일을 업로드하면 인증서가 준비되는데 보통 `ios_development.cer`로 저장된다.
  - provisioning profile을 생성한다.

    - description

      - 인증받은 개발자라는 사실을 기기에 전달하기 위해 profile이 필요하다.
      - 개발자 계정과 기기를 연결하는 역할을 담당한다.
      - 아래와 같은 3가지 요소가 profile에 포함된다.

        - 인증서
        - app id
        - 디바이스

        <img src="https://hcn1519.github.io/public/postImages/2018-10/ios_codesigning_provisioningprofile/provisioningProfile.png" width="500">

    - process
      - **Provisioning Profiles - Development**를 선택하고 옵션을 선택한다.
      - 위에서 만들어준 app id를 입력하고 다음으로 넘어간다.
      - profile을 만들때 사용할 인증서를 선택한다.
      - 필요한 디바이스를 선택하고 profile 명을 정해준다.
      - 생성된 파일을 xcode에서 **General - Singing - Provisioning Profile**에 import해준다.
      - 정상적으로 진행되었으면 경고/에러 없이 정상적인 화면을 볼 수 있다.
      - 배포용 인증서 및 profile을 만드는 방법도 거의 동일하다.

## 07.05.2020

- push notification

  - 개발인증서, 프로파일을 등록한다.
  - apn key 발급 및 app id를 등록한다.
  - firebase 프로젝트를 생성한다.
  - fcm에 apn key 및 app id를 등록한다.
  - xcode 프로젝트에서 capabilities를 추가한다.
  - app을 apn에 등록한다.
  - apn에서 보내준 deviceToken을 받아서 fcm에 전달한다.
  - fcm에서 보내준 fcmToken을 앱 서버에 보내서 알림을 받을 수 있게 설정한다.
  - fcm에서 메시지를 발송한다.
  - 앱에서 userInfo를 통해 메시지를 받아서 푸시알림을 요청한다.

- fcm

  - fcm에서 보내주는 단일 알림 메시지
  - fcm에서 보내주는 데이터 + 알림 메시지 - 로컬 알림 메시지

- ios
  - 개발용: device, certificate, provisioning profile
  - 배포용: certificate, provisioning profile
  - 기타: app id, identifier, app key

## 08.05.2020

- elasticsearch

  - term

    - data node
      - 데이터와 관련된 crud 작업을 하는 노드이다.
      - 자원을 많이 소모해서 모니터링이 꼭 필요하며, master 노드와 분리하는 것이 좋다.
    - ingest node
      - 데이터를 변환하는 등 사전처리 파이프라인을 실행하는 역할을 한다.
    - coordinating only node
      - data node와 master-eligible의 일을 대신하는 이 노드는 대규모 클러스터에서 큰 이점이 있다.
      - 로드밸런서와 같은 역할을 한다.
    - machine learning node
      - 머신러닝 관련 api를 제공한다.

    <img src="https://media.vlpt.us/images/labyu/post/e37f2696-72f8-478e-af0c-ea08f13e0907/%EB%8B%A4%EC%9A%B4%EB%A1%9C%EB%93%9C%20(3).png" width="500">

  - query

    ```json
    GET /<index>/_search
    {
      "from": 0,  // offset
      "size": 10, // limit
      "_source" : [
        // RDBMS의 SELECT * 라고 보면됨, 이곳에 key쓰면 그것만 가져옴
      ],

      "query": {
        // Query DSL이 올 자리
      }
    }
    ```

    - full text search: 검색하기 전 analyze한다.

      - short match: analyzed text에서만 검색한다.

        ```json
        GET /<index>/_search
        {
          "from": 0,  // offset
          "size": 10, // limit
          "_source" : [
            "FIELD"
          ],

          "query": {
            "match": {
              "FIELD" : "VALUE"
            }
          }
        }
        ```

      - long match: white space를 기준으로 and/or 연산이 가능하다.

        ```json
        GET /<index>/_search
        {
          "from": 0,  // offset
          "size": 10, // limit
          "_source" : [
            "FIELD"
          ],

          "query": {
            "match": {
              "FIELD" : {
                "query" : "VALUE WITH WHITE SPCAE",
                  "operator" : "and"
              }
            }
          }
        }
        ```

      - multi match: 여러 필드에서 쿼리를 사용할 수 있다.

        ```json
        GET /<index>/_search
        {
          "from": 0,  // offset
          "size": 10, // limit
          "_source" : [
            "FIELD1",
            "FIELD2"
          ],

          "query": {
            "multi_match" : {
              "query":  "VALUE",
              "fields": [ "FIELD1", "FIELD2" ]
            }
          }
        }
        ```

    - term level query: keyword 필드에서만 검색한다. 검색 전에 analyze하지 않는다.

      - wildcard: rdb에서 `LIKE '%VALUE%'`와 같다. boost는 가중치이다.

        ```json
        GET /<index>/_search
        {
          "from": 0,  // offset
          "size": 10, // limit
          "_source" : [
            "FIELD"
          ],

          "query": {
            "wildcard": {
              "FIELD" : {
                "value" : "*VALUE*",
                  "boost" : 1.0
              }
            }
          }
        }
        ```

      - range: 날짜/범위 검색에 굉장히 편리하다. 특히 date_range로 저장하면 편하다.

        ```json
        GET /<index>/_search
        {
          "from": 0,  // offset
          "size": 10, // limit
          "_source" : [
            "FIELD"
          ],

          "query": {
            "range" : {
              "FIELD" : {
                "gte" : "시작",
                "lt" :  "끝"
              }
            }
          }
        }
        ```

    - compound query: 다른 쿼리들을 결합해서 사용할 수 있도록 도와준다.

      - must: must 아래의 쿼리들이 `true`일 때 데이터를 가져온다.

        ```json
        GET /<index>/_search
        {
          "from": 0,  // offset
          "size": 10, // limit
          "_source" : [
            "FIELD"
          ],

          "query": {
            "bool" : {
              "must" : [
                  {
                    "match" : {
                      "FIELD1" : "VALUE"
                      }
                    },
                  {
              "match" : {
                  "FIELD2" : "VALUE"
                 }
                }
              ]
            }
          }
        }
        ```

      - should: should 아래의 쿼리들이 하나만 `true`라도 데이터를 가져온다.

        ```json
        GET /<index>/_search
        {
          "from": 0,  // offset
          "size": 10, // limit
          "_source" : [
            "FIELD"
          ],

          "query": {
            "bool" : {
              "should" : [
                {
                  "match" : {
                    "FIELD1" : "VALUE"
                  }
                },
                {
                  "match" : {
                    "FIELD2" : "VALUE"
                  }
                }
              ]
            }
          }
        }
        ```

      - must_not: must_not 아래의 쿼리들이 모두 `false`일 때 데이터를 가져온다.

  - analyzer
    - index를 생성할 때 만들며, 이 때 고려해야 할 것들은 아래와 같다.
    - analyzer에 tokenizer, filter를 등록 후, mapping에서 analyzer를 설정한다.
    - token filter: token을 중복토큰을 제거할 수 있는 필터링 기능이다.
    - character filter: html태그 등을 제거할 수 있는 문자열에 대한 필터링 기능이다.
    - tokenizer: full text의 inverted index를 만들기 위해 사용하는 형새토 분석기이다.
    - nomarlizer

## 09.05.2020

- fp
  - IO: 참조 투명성을 깨는 부분을 제어할 수 있게 도와주는 함수자이다.
    ```ts
    class IO {
      static of(value) {
        return new IO(() => value);
      }
      constructor(fn) {
        this.value = fn;
      }
      map(fn) {
        return new IO(pipe(this.value, fn));
      }
      runIO() {
        return this.value();
      }
    }
    ```
  - monad chaining
    - 어떤 함수의 반환 값이 어떠한 값일지라도 함수자인 경우 map을 이용해서 연결할 수가 있다.
    - chain 메서드를 구현한 객체이다. chain 메서드는 모나드가 가진 값에 함수를 적용해서 새로운 모나드를 반환해야한다.

## 10.05.2020

- big-o

  - 알고리즘의 효율성을 수학적으로 표기하는 방식이며, 시간과 공간복잡도를 표현한다.
  - 데이터 증가에 따른 알고리즘 성능 측정에 목적을 두고 있다.
  - O(1)
    - 각 인풋 공간에 변화가 없다.
    - constant time이라고 부른다.
      ```js
      function constant(n) {
        return n * n;
      }
      ```
  - O(N)
    - 최악의 경우 n개의 연산을 수행해야 하는 경우 적용된다.
    - 대부분 간단한 반복문 안에서 constant time 연산을 하는 경우이다.
    - linear time이라고 부른다.
      ```js
      function linear(n) {
        const arr = [];
        for (let i = 0; i < n; i++) {
          arr[i] = i;
        }
        return arr;
      }
      ```
  - O(log(n))
    - 실행 시간이 입력크기의 로그에 비례한다.
    - logarithmic time이라고 부른다.
      ```js
      function log(n) {
        const arr = [];
        for (let i = 1; i < n; i *= 2) {
          arr.push(i);
        }
        return arr;
      }
      ```
  - O(n2)
    - 인풋의 크기에 따라 2차식으로 속도에 영향을 미치는데 예를들자면 에중 반복문이 있겠다.
    - 안에 있는 반복문은 밖에 있는 반복문의 값과 상관없이 항상 n번 실행된다.
    - quadratic time이라고 부른다.

  <img src="https://media.vlpt.us/images/qksud14/post/4ac0c4a2-8f0c-48c0-8ed3-11d985d7339a/bigO.jpeg" width="500">

- javascript

  - `Array.prototype.shift()`: 배열에서 첫 번째 요소를 제거하고 제거된 요소를 반환한다.
  - `Array.prototype.unshift()`: 새로운 요소를 배열의 맨 앞에 추가하고 새로운 길이를 반환한다.

- sorting algorithm

  - quick: 배열의 하나의 값을 정해서 그 값보다 큰 값은 오른쪽에 적은 값은 왼쪽에 위치시키고 이를 반복해 정렬한다. 일반적으로 많이 사용하는 방법으로 보이며 `sort()` 메서드가 퀵정렬로 구현되어있다. 시간복잡도는 O(nlogn)이다.
    ```js
    const quickSort = (arr) => {
      if (arr.length === 0) return [];
      let left = [];
      let right = [];
      let pivot = arr[0];
      for (let i = 1; i < arr.length; i++) {
        if (arr[i] < pivot) {
          left.push(arr[i]);
        } else {
          right.push(arr[i]);
        }
      }
      return quickSort(left).concat(pivot, quickSort(right));
    };
    ```
  - merge: 배열을 반으로 나누고 계속 나눠서 배열의 요소가 1개가 될 때까지 나눈다. 나누어진 배열을 각 정렬에 위치시켜 합치는 구조이다. 시간복잡도는 O(nlogn)이다.

    ```js
    const mergeSort = (arr) => {
      if (arr.length < 2) return arr;
      const pivot = Math.floor(arr.length / 2);
      const left = arr.slice(0, pivot);
      const right = arr.slice(pivot, arr.length);
      return merge(mergeSort(left), mergeSort(right));
    };

    const merge = (left, right) => {
      const res = [];
      while (left.length && right.length) {
        if (left[0] <= right[0]) {
          res.push(left.shift());
        } else {
          res.push(right.shift());
        }
      }
      while (left.length) res.push(left.shift());
      while (right.length) res.push(right.shift());
      return res;
    };
    ```

  - bubble: 순차적으로 바로 옆에 있는 데이터와 비교해서 옆의 데이터가 더 크면 자신과 위치를 교환한다. 이러한 형태가 마치 거품이 보글보글 올라가는 것과 비슷해보여서 붙여진 이름이다. 시간 복잡도는 O(N2)이다.
    ```js
    const bubbleSort = (arr) => {
      let res = [...arr];
      for (let i = 0; res.length - 1; i++) {
        for (let j = 0; j < res.length - i; j++) {
          if (res[j] > res[j + 1]) {
            let temp = res[j];
            res[j] = res[j + 1];
            res[j + 1] = temp;
          }
        }
      }
      return res;
    };
    ```
  - insertion: 정렬된 부분과 정렬되지 않는 부분으로 나눠서 해당 요소가 정렬된 부분보다 값이 적다면 요소 교환을 하는 알고리즘이다. 시간복잡도는 O(N2)이다.

    ```js
    const insertionSort = (arr = []) => {
      let res = [...arr];
      for (let i = 1; i < res.length; i++) {
        let temp = res[i]; // 현재값 저장
        let aux = i - 1; // 정렬된 부분의 현재 인덱스

        // 좌측 값이 현재 값보다 클 때 스왑
        while (aux >= 0 && res[aux] > temp) {
          res[aux + 1] = res[aux];
          aux--;
        }

        // 임시로 저장한 현재값을 정렬된 부분의 인덱스에 부여
        res[aux + 1] = temp;
      }
      return res;
    };
    ```

  - selection: 정렬되지 않은 배열 중 현재 위치에 맞는 값을 선택해서 위치를 교환한다. 비교알고리즘 중 하나이므로 O(N2)의 시간복잡도를 갖는다.

    ```js
    const selectionSort = (arr = []) => {
      let res = [...arr];
      for (let i = 0; i < res.length - 1; i++) {
        // 현재 인덱스를 최소값이라고 가정한다.
        let minNum = i;

        // 정렬되지 않은 배열에서만 탐색하기 위해 j를 i + 1로 설정한다.
        for (let j = i + 1; j < res.length; j++) {
          if (res[minNum] > res[j]) {
            minNum = j;
          }
        }

        // 스왑
        if (minNum !== i) {
          let temp = res[minNum];
          res[minNum] = res[i];
          res[i] = temp;
        }
      }
      return res;
    };
    ```

## 11.05.2020

- react-native-firebase v6 migration

  - ios
    - RNFirebase 팟 제거
    - Firebase Core 및 특정 팟 제거
    - `Podfile.lock` 제거 및 팟 재설치
  - android

    - `/android/settings.gradle`에서 아래 라인 제거

      ```java
      rootProject.name = 'AwesomeApp'
      // include ':react-native-firebase'
      // project(':react-native-firebase').projectDir = new File(rootProject.projectDir, '../node_modules/react-native-firebase/android')

      include ':app'
      ```

    - react-native-firebase 의존성 제거
      ```java
      dependencies {
      // implementation "com.google.firebase:firebase-core:16.0.9"
      // implementation "com.google.android.gms:play-services-base:16.1.0"
      }
      ```
    - gradle 의존성 제거

## 13.05.2020

- aws
  - ec2
    - 딥러닝 특화 서버인 sage maker도 제공한다.
    - general purpose: 평균적인 사양을 제공한다.
    - compute optimized: 다른 인스턴스에 비해 vcpu 비율이 높다.
    - memory optimized: 메모리 용량이 매우 크다.
    - accelerated computing: gpu가 달려있다.
    - storage optimized: 스토리지 용량이 크고 고속 i/o를 제공한다.
    - micro instance: 보통 프리티어용이다.
  - elastic cache
    - 인스턴스라 부르지 않고 대신 캐시노드라고 부른다. 처음 사양설정은 가능하지만 이후 변경은 불가능하다.
    - 캐시노드에 접속하려면 동일한 vpc에 속한 ec2에서만 가능하다.
    - s3를 통해 rdb 백업과 마이그레이션이 가능하다.
    - redis
      - 캐시노드가 지원하는 메모리 용량을 넘어서는 데이터를 저장하려면 샤딩 필요함
      - 클러스터 지원 없음
      - 스냅샷 지원기능 있음
      - 읽기 레플리카 지원 있음
      - 마스터/슬레이브 간 자동승격기능 있음
      - 클러스터링
    - memcached
      - 가용영역 별 클러스터 지원
      - 스냅샷 지원기능 없음
      - 읽기 레플리카 지원 없음

## 14.05.2020

- aws
  - ebs
    - iops: Input/Ouput Operation Per Second. 저장장치 성능 측정단위로 올리면 추가로 과금이 발생한다.
  - sg
    - inbound: 외부에서 인스턴스로 들어오는 트래픽으로 http, https, ftp, ssh 등이 있다.
    - outbound: 기본적으로 모든 트래픽을 허용한다. 인스턴스에서 외부로 나가는 트래픽을 말한다.
    - type: 프로토콜 형태로 tcp, udp, icmp 등이 있다.
    - port/port range
    - source/desination: 연결 혹은 접속가능한 ip 대역으로 cidr 표기법을 사용한다.
  - elastic ip
    - dns를 연결하고 관리하기 위해서는 고정 ip가 필요한데, 할당만 받더라도 요금이 과금된다.
  - ami: Amazon Machine Images
  - cloud watch
    - 예시조치
      - auto scaling
      - events를 통해 운영 변경사항에 대한 대응 자동화
      - eks, ecs에 경보제공 및 작업 자동화
    - 사용사례
      - 인프라 모니터링 및 문제해결
      - 평균 문제해결 시간 개선
      - 사전 리소스 최적화
      - 애플리케이션 모니터링
      - 로그 분석
    - 얻을 수 있는 지표
      - ec2 instance: cpu 사용률, 데이터 전송량, 디스크 사용량
      - ebs volume: 읽기/쓰기 사용량, 지연시간
      - elb: 요청수, 지연시간
      - rds: cpu 사용률, db 연결수, 사용가능한 메모리/스토리지, 읽기/쓰기 지연시간
      - dynamo db: 테이블 인덱스, 글로벌/로컬 보조 인덱스에 소모한 읽기/쓰기 용량 유닛, 스캔, 쿼리
      - elastic cache: cpu 사용률, 데이터 읽기/쓰기, 네트워크 사용량, 캐시엔진
      - sns: 생성/전달 여부
      - sqs: 송수신 카운트
  - s3
    - object
      - s3에 저장되는 데이터의 최소단위로 파일과 메타데이터로 구성된다.
      - key/value 형식이다.
      - 한 객체당 1byte ~ 5tb까지 저장이 가능하다.
      - 메타데이터는 http mime이다.
    - bucket
      - s3에 생성하느 최상위 디렉토리로 리전별로 생성해야하지만 이름은 유니크해야한다.
      - 저장 가능한 용량과 객체 수는 무한이다.
      - 디렉토리 생성이 가능하지만 실제로는 객체 이름 디렉토리 경로까지 포함된다.
      - 접속 제어 및 권한 관리가 가능하다.
    - storage class
      - standard storage: 100에 수렴하는 내구성을 가지지만 비싸다.
      - reduced redundancy storage: 비교적 낮은 내구성을 가지지만 저렴하다.
    - bucket policy: generator를 이용해 만들어 정책 설정에 복붙해준다.
      - select type of policy: 정책 타입을 설정한다.
      - effect: 허용/거부인지에 대한 여부이다.
      - principal: 권한을 적용할 사용자이다. 현재 이 bucket의 모든 object를 online으로 public하게 제공할 것이기때문에 `*`를 사용한다.
      - aws service: type 설정시 자동으로 설정된다.
      - action: `GetObject` 등의 액션을 설정할 ㅜㅅ 있다.
      - arn: 리소스 이름으로 `arn:aws:s3:::<bucket_name>/<key_name>` 등을 사용해 만들 수 있다. s3 관리메뉴 bucket 목록에서 arn을 복사할 수 있다.
      - add condition: 어떤 조건에만 접근가능하도록 url 필터를 걸어줄 수 있다.
    - bucket cors: cors를 설정해야 이후 웹서버에서 사용할 수 있다.
    - version control
    - server access logging: s3에 저장된 object의 로그를 파일형태로 남길 수 있다.
    - static website hosting
    - encryption
  - cloud front
    - s3에 있는 파일을 바로 사용자가 접근하는 것이 아닌 cloud front에 캐시해두었다가 사용하기때문에 빠른 접근 속도를 가질 수 있다. 
    - 설정 직후에는 수 분이 지나야 cloud front로 s3에 접속할 수 있다. 
    - s3에서 public object를 생성해서 cloud front로 접속이 된다면 잘 설정된 것이다.
    - 다음부터는 private하게 사용하더라도 cloud front로 접속이 된다.
    - status가 deployed로 되면 모든 edge location으로 배포된 이후이고 그때부터 사용이 가능하다.
    - domain name이 접근할 수 있는 public url이고 s3 bucket root url을 가리킨다.
    - origin
      - cdn 서비스이기때문에 항상 원본에서 파일을 가져와야한다. 이 때 원본서버가 origin이다. 다음과 같은 것들만이 origin이 될 수 있다.
        - s3 bucket
        - ec2 instance
        - elb
        - web server
    - distribution
      - web
      - rtmp: 스트리밍용 프로토콜 
    - origin domain name: s3 목록이 나오면 선택할 수 있다.
    - origin path: s3 bucket의 특정 디렉토리를 사용하고 싶을 경우 사용한다. root에서 자동으로 redirection된다.
    - restrict bucket access: s3 bucket에 cloud front만 접근할 수 있도록 설정하는 옵션이다.
    - origin access identity: origin에 접근할 식별자를 말한다.
    - comment: 새로 생성할 식별자 이름이다.
    - grant read permission on: cloud front가 s3의 object 읽기 권한을 s3 bucket policy에 업데이트시킨다.
    - path pattern: 파일을 가져올 때 사용하는 규칙으로 `*`면 모두 가져온다.
    - viewer protocol policy: production에서는 **https only**나 **redirect http to https**를 권장한다.
    - allowed http methods: method를 추가하면 컨텐츠 전송이 가능해진다.
    - ttl: Time to Live 설정을 한다.
    - forward cookies, query string: 요청시 필요한 cookies/qs가 있다면 사용할 수 있지만 캐싱 성능을 떨어뜨리므로 권장하지는 않는다.
    - smooth streaming
    - price class: edge location 사용범위를 설정한다.
    - aws waf web acl: web application firebwall 사용여부를 선택할 수 있다.
    - ssl certificate
      - default cloud front certificate: cloud front에서 기본적으로 제공하는 인증서이다.
      - custom ssl certificate: acm을 이용해 만들 수 있다.
    - default root object `/`에서 보여줄 파일을 입력해준다.
    - logging
      - bucket for logs: 로그 저장용 s3 bucket을 선택할 수 있다.
      - log prefix: 로그를 저장할 때 디렉토리명을 설정할 수 있다.
    - distribution state: enabled면 바로 사용이 가능하다.

## 15.05.2020

- aws
  - rds
    - read replica
      - 읽기 복제본 생성을 선택해 진행한다.
      - replica는 읽기작업만 가능하다.
      - promote read replica를 설정하면 slave를 master로 승격시킬 수 있다.
      - replica도 vpc와 public access를 설정해주어야 접속 가능하다.
      - replica 생성시 새로운 스냅샷을 만들고 그 스냅샷으로 replica를 만든다.
      - 고정 ip를 할당받지 않았다면 master instance의 endpoint가 변경되니 다시 연결해야 한다.
  - dynamo db
    - table: 아이템들의 집합이다.
    - item: 속성들의 집합이다.
    - attribute: key/value 방식의 데이터이다.
    - attribute data type: number, string, binary, number/string/binary set
    - index: table 생성 시 한 번 생성하면 이후 수정/삭제/추가가 불가능하다. 
      - index type: 테이블을 생성할 때 pk로 index를 설정해야 한다.
        - hash: 속성 하나를 pk로 한다. 일치 방식의 검색만 가능하다.
        - range: 속성 두 개를 pk로 한다. 일치/부등포/포함 등의 검색이 가능하다.
      - secondary index: 각각 5개까지 생성이 가능한 보조 인덱스이다.
        - local
        - global
    - read type: 처리량으 ㄹ미리 지정해 사용한다.
    - provisioned throughput
      - read capacity units
      - write capacity units
    - inquiry type
      - scan: 데이터를 모두 가져온다.
      - query: 쿼리를 통해 지정한 조건 범위에서 데이터를 가져온다.
  - route 53
    - dns 서비스로 ec2, elb, s3, cloud front 등에 적용가능하다.
    - 주요기능
      - resolver
      - latency based routing: 현재 위치에서 지연시간이 가장 낮은 리전의 ip 주소를 반환한다.
      - weighted round robin: ip마다 가중치를 부여해서 가중치 퍼센트에 따라 트래픽을 부여한다.
      - dns failover: 장애가 발생한 ip로는 트래픽을 보내지 않는다.
      - geo routing: 현재 사용자가 접속한 지역에 따라 다른 ip를 반환한다.

## 16.05.2020

- aws
  - route 53
    - dns 생성
      - www를 제외한 구입한 도메인을 입력한다.
      - 네임서버의 값을 도메인을 구입한 사이트에 가서 적용한다.
      - 도메인 앞에 붙는 주소인 a 레코드를 생성하는데, 아무것도 입력하지 않으면 도메인명 그대로 생성된다.
    - s3와 연동해 정적 웹페이지 제공
      - 버킷의 정적호스팅 옵션을 설정해준다.
      - a 레코드와 cname을 생성한다.
    - cloud front와 연동
    - dns failover
      - elastic ip를 켜고 80번 포트 아웃바운딩된 ec2 2대를 준비한다.
      - route 53 상태검사를 설정한다.
      - 요청간격, 실패시 재시도 횟수 등을 설정한다. 
  - elb
    - l4: transport 계층을 뜻하고, tcp/udp 등의 프로토콜을 포트로 구분한다. netwokr 계층의 ip와 l4의 포트를 기준으로 트래픽을 분배한다.
    - l7: application 계층을 뜻하고, http 프로토콜의 헤더를 기준으로 트래픽을 분배한다.
    - connectin draining: auth scaling이 사용자의 요청을 처리중인 ec2 instance를 바로 삭제하지 못하도록 방지하는 기능이다.
    - sticky session: 사용자의 세션을 확인해서 적절한 ec2 instance로 트래픽을 분배하며, l7 lb의 기능이다.
    - surge queue length: elb에서 ec2로 전달되지 못하고 큐에 남아있는 요청 수를 말한다.
    - spillover count: 서지 큐가 모두 차서 elb가 거부한 요청 수를 말한다.
  - vpc
    - subnet: vpc의 ip 주소 범위를 말한다. 지정된 서브넷으로 리소스를 실행할 수 있으며 인터넷이 필요하다면 퍼블릭으로, vpn 연결 등이 필요하다면 프라이빗을 이용한다.
      - public
      - private: site-to-site vpn 연결을 위한 가상 private gateway로 라우팅되는 경우를 말한다.
    - site-to-site: 인트라넷을 구성하려는 경우에 이 전략을 사용한다.
  - eb
    - 옵션구성을 통해 ec2, rds 모니터링 등 환경설정을 할 수 있다.
    - 설정없이 그냥 실행시키면 nginx 기본 프락시 포트인 `8080`으로 잡히므로 다른 포트를 사용하려면 설정이 필요하다.
    - 무중단 배포를 하려면 환경을 하나 더 만들어서 배포 후 swap하면 된다.

## 17.05.2020

- test
  - test double
    - 역할
      - 테스트 대상 코드와 상호작용하는 객체이다.
      - 테스트 대상 코드를 격리한다.
      - 테스트 속도를 개선한다.
      - 예측 불가능한 실행 요소를 제거한다.
      - 특수한 상황을 시뮬레이션한다.
      - 감춰진 정보를 얻어낸다.
    - 종류
      - dummy
        - 가장 기본적인 테스트 더블 유형이다.
        - 구현이 포함되어있지 않고 매개변수 값으로만 필요하며 다른 곳에 이용되지 않는 경우 주로 사용한다.
        - 해당하는 객체의 기능까지 필요없는 경우 사용한다.
        - dummy 객체의 메서드가 호출된 경우 정상동작을 보장하지는 않는다.
        - 보통 타입의 기본값으로 반환값을 만들어주는 선에서 마무리한다.
      - stub
        - dummy 객체가 실제로 동작하는 것처럼 보이게 만들어놓은 객체이다.
        - 실제 코드나 아직 준비되지 못한 코드의 행동으로 가장하는 매커니즘을 말한다.
        - 호출자를 실제 구현물로부터 격리시킬 목적으로 런타임에 실제 코드 대신 삽입하는 코드 조각이다.
        - 가장 큰 목적은 원래의 구현을 최대한 단순한 것으로 대체하는 것이다.
        - dummy보다 한 단계 발전한 형태로 인터페이스나 클래스를 최소한으로 구현한 형태이다.
        - 일반적으로 void를 반환하는 메서드는 구현이 없고 값을 반환한느 메서드는 하드코딩한 값을 반환한다.
        - 대부분의 경우 stub을 이용한 테스트의 신뢰도는 높은 편이다.
        - 파일시스템이나 서버와의 커넥션 등 외부 시스템 전체를 대체하는데 주로 활용할 수 있다.
        - 반드시 stub은 단순해야 하며 절대 테스트나 유지보수가 요구되는 또 하나의 프로그램이 되어서는 안된다.
      - fake
        - stub은 하드코딩된 형태이므로 로직이 들어가는 부분은 테스트할 수 없다.
        - 마치 실제 로직을 구현한 것처럼 보이는 객체를 fake라고 한다.
        - stub보다 비교적 복잡한 로직인 경우를 말한다.
      - spy
        - 테스트에 특정 객체가 사용되는지 그 객체의 예상 메서드가 정상적으로 호출됐는지를 확인하는 경우 사용한다.
        - spy는 아주 특수한 경우를 제외하고 잘 쓰지 않는데 보통 mock 프레임워크를 사용하는 것이 더 편하기때문이다.
      - mock: 테스트 더블이란 단어와 mock 객체가 거의 동등한 의미로 사용하는 경우가 더 많다.
        - state based
          - 객체가 특정 시점에 자신만의 상태를 갖는 특징에 기반한 테스트 방식이다.
        - behavior based
          - 보통 메서드의 리턴값이 없거나 리턴값을 확인하는 것만으로 예쌍대로 동작했음을 보증하기 어려운 경우에 사용한다.
          - `foo()`가 정상동작한 경우 `bar()`가 반드시 호출되는 구성이라면 `bar()`의 호출여부로 `foo()`의 정상여부를 판단할 수 있다고 보는 것이다.
          - 초창기에 나온 mock 프레임워크 태생 자체가 행위기반 테스트를 기원하기 위한 경우가 대다수이다.
  - 규칙
    - given-when-then 패턴을 유지한다.
      - 준비: 테스트에 사용하는 변수, 입력값 등을 정의하거나 mock 객체의 정의를 하는 구문이 포함된다.
      - 실행: 실제로 액션을 하는 테스트를 실행하는 과정이다. 가장 중요한 구문이지만 가장 짧다.
      - 검증: 예상한 값, 실제 실행을 통해 나온 값을 검증한다.
    - given이 길어지는 경우가 많아서 종류별로 순서를 정해두는 것이 좋다.
      - dummy 데이터 정의
      - 테스트더블 객체 정의
      - dom 객체나 instance 객체속성 설정
    - 명세의 내용을 테스트코드가 번역한다는 느낌으로 작성한다.
      - 잘 짠 테스트 코드를 읽으면서 명세의 내용이 그대로 테스트 코드로 바뀌는 것처럼 자연스럽게 읽힌다는 것을 느꼇다.
      - 명세를 적고 코드를 작성한 뒤 서로가 잘 매취되어 읽히는지도 확인한다.
    - 명세는 개발자보다 사람이 이해하기 좋은 스토리로 쓰는 것이 테스트하기 좋다.
    - 라이브러리 의존성을 낮추는 코드를 지향한다.
    - 추상화수준으로 메서드를 구분하기보다는 로직의 복잡성 정도로 판단하는 것이 좋다.
      - 단순한 로직의 하위레벨 메서드는 상위레벨 메서드에서 한 번에 테스트한다. 
      - 복잡한 로직의 하위레벨 메서드는 상위레벨 메서드에서 spy나 stub을 호출해 최종 결과값만 체크하고 하위레벨 메서드에 대한 상세한 테스트를 별도로 작성한다.
    - 클라이언트 템플릿 렌더링 테스트는 dom list 전체 개수, list 한 개의 주요 속성값을 비교하는 것이 좋다.
    - 웹 스토리지는 가짜 객체를 만들어 테스트하는 것이 좋다.
    - 이벤트 테스트는 실제 dom에서 이벤트를 발생시키는 방향으로 작성한다.

- gof design pattern
  - creational
    - abstract factory: 동일한 주제의 다른 팩토리를 묶어준다.
    - builder: 생성과 표기를 분리해 복잡한 객체를 생성한다.
    - factory method: 생성할 객체의 클래스를 국한하지 않고 객체를 생성한다.
    - prototype: 기존 객체를 복제함으로서 객체를 생성한다.
    - singleton: 한 클래스에 한 객체만 존재하도록 제한한다.
  - structural
    - adapter: 인터페이스가 호환되지 않는 클래스들을 함께 이용할 수 있도록 타 클래스의 인터페이슬ㄹ 기존 인터페이스에 덧쓰운다.
    - bridge: 추상화와 구현을 분리해 둘을 각각 따로 확장시킬 수 있다.
    - composite: 여러개의 객체를 묶어 하나의 객체로 이용할 수 있다.
    - decorator: 기존 객체의 메서드에 새로운 행동을 추가하거나 오버라이딩할 수 있다.
    - facade: 많은 분량의 코드에 접근할 수 있는 단순한 인터페이스를 제공한다.
    - flyweight: 다수의 유사한 객체를 생성/조작하는 비용을 절감할 수 있다.
    - proxy: 접근 조절, 비용절감, 복잡도 감소를 위해 접근이 힘든 객체에 대한 대역을 제공한다.
  - behavioral
    - chain of responsibility: 책임들이 연결되어 있어 내가 책임을 못질 것 같으면 다음 책임자에게 자동으로 넘어가는 구조이다.
    - command: 명령어를 각각 구현하는 것보다는 하나의 추상 클래스에 메서드를 하나 만들고 각 명령이 들어오면 그에 맞는 서브 클래스가 선택되어 실행시키는 것을 말한다.
    - interpreter: 문법 규칙을 클래스화한 구조를 갖는 sql이나 프로토콜 같은 것을 개발할 때 사용한다.
    - iterator: 반복이 필요한 자료구조를 모두 동일한 인터페이스를 통해 접근할 수 있도록 메서드를 이용해 자료구조를 활용할 수 있도록 도와준다.
    - observer: 어떤 클래스에 변화가 일어났을 때 이를 감지해 다른 클래스에 알려주는 구조이다.
    - strategy: 알고리즘 군을 정의하고 각각 하나의 클래스로 캡슐화한 다음, 필요할 때 서로 교환해서 사용할 수 있도록 해준다.
    - template method: 상위클래스에서는 추상적으로 표현하고 그 구체적인 내용은 하위클래스에서 결정하는 패턴이다.
    - visitor: 각 클래스의 데이터구조로부터 처리기능을 분리해 별도의 클래스로 만들어두고, 해당 클래스의 메서드가 각 클래스를 돌아다니며 특정 작업을 수행하도록 하는 것을 말한다.
    - mediator: 클래스간의 복잡한 상호작용을 캡슐화해서 한 클래스에 위임해서 처리하는 패턴이다.
    - state: 동일한 동작을 객체의 상태에 따라 다르게 처리할때 사용하는 패턴이다.
    - memento: undo 기능을 개발할 때 유용하다.

- threat medeling: ms에서 대중화한 개념으로 잠재적인 위협을 모델링하고 이를 완화할 수 있는 프로세스를 말한다. 시스템의 특성과 방어시스템을 고려했을 때 어떤 부분에 있어서 방어가 필요하고 보안상 취약할 수 있는지 가능성을 찾는 것으로 특히 특정한 위협포인트에 대해 미지수일 경우 가능한 취약점을 찾는 것이 된다. 공격자의 입장으로 시뮬레이션 해보고 공격 측면을 찾아내는 일이 포함된다.
  - stride
    - spoofing: 공격자가 권한이 있는 사용자인척 위장하는 공격 방식
    - tampering: 목적을 위해 시스템 내부 데이터를 악의적으로 수정하는 공격 방식
    - repudiation: 악의적 활동 이후에 해당 활동에 대해 부인하는 것
    - information disclosure: 보호된 정보에 대한 노출을 하는 행위
    - denial of serivce: 서비스에 대한 믿을 수 있는 접근을 바탕으로 한 공격. 분산해서 공격하는 것을 ddos라고 함
  - dread: 아래의 수치의 평균을 risk로 정의한다.
    - damage potential: 취약점이 노출되었을 경우 발생 가능한 피해량
    - reproucibility: 재공격 당하기 쉬운 정도
    - exploitability: 공격을 하기 위해 필요한 공수
    - affected users: 위협이 얼마나 많은 유저에게 노출되는지
    - discoverability: 얼마나 위협을 탐지하기 쉬운지
  - pasta: Process for Attack Simulation and Threat Analysis. 직접 위협 요소를 검증하고 위협 요소들에 대해 점수를 부여해서 분석하고 완화시키기 위한 방법을 개발자에게 제시하는 것을 목적으로 한다.
  - vast: Visual, Agile and Simple Threat modeling. 인프라 및 시스템 전체에 대한 모델링이 필요하며 agile 프로세스에 위협 모델링 정보를 시각화할 수 있는 부분으 포함한다. 전문적 지식 없이 간단하게 진행한다. 

## 18.05.2020

- aws
  - elb
    - 로드밸런싱 이외에 dns를 구성해 트래픽을 분산하거나 nginx를 reverse-proxy 서버로 구성해 트래픽을 분산하는 방법도 있다. 다만 이렇게 구성한 경우 single point of failure를 신경써야한다.
    - elb로 구성할경우 ec2 인스턴스는 두 개 이상으로 구성해야하고, 상태 체크 인터페이스를 따로 구현하고 임계값 등을 설정해 lb가 해당 인스턴스를 제외하거나 포함하도록 설정해야한다.
    - ec2에 배포하는 경우에는 서비스가 중단될 수 있으므로 `delete-load-balanser`를 통해 로드밸런서 그룹에서 제외한 다음 배포해야 한다.
  - acm
    - s3에 인증서를 사용하기 위해서는 north-virginia의 인증서를 생성해야 가능하다.
  - rds
    - 복제 기능 구성에서 aurora가 더 향상된 기능을 제공하고 있다.
    - read/write 구분은 orm단에서 쉽게 설정이 가능하다.
  - sqs
    - rds에 write할 때에도 사용할 수 있다.
