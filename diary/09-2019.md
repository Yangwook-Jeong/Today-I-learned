# 오늘 배운 것을 정리하는 공간

## 04.09.2019

- storm proxy: 프록시를 씌우는 서비스

## 05.09.2019

- apache spark
  - 하둡을 이용한 정보활용하기 위한 데이터 프로세싱 툴이다.
  - 하둡을 통해 끌어오는 데이터들은 시간 소요가 크기때문에 실시간으로 분석해야 하는 업무에서는 어려운 부분이 있어 개발되었다.
  - 스칼라를 사용해 인터렉티브 쉘을 사용할 수 있다.
  - 분산처리를 하둡보다 빠른 속도로 하는 도구이다.
  - 빅데이터 애플리케이션에 필요한 대부분의 기능을 지원한다.
  - 기능
    - 맵리듀스와 유사한 일괄처리 기능이 있다.
    - 실시간 데이터 처리기능 (spark streaming)
    - sql과 유사한 정형 데이터 처리기능 (spark sql)
    - 그래프 알고리즘 (spark graph x)
    - 머신러닝 알고리즘 (spark mlib)
  - 장점
    - 메모리 효율을 높여서 하둡의 맵리듀스보다 10-100배 빠르게 설계되었다.
    - 맵리듀스처럼 job에 필요한 데이터를 디스크에 매번 가져오는 대신, 데이터를 메모리에 캐시로 저장하는 in-memory 실행 모델로 비약적으로 성능을 개선해싿.
    - 머신러닝, 그래프 알고리즘 등 반복알고리즘과 기타 데이터를 재사용하는 모든 유형 작업에 많은 영향을 준다.
    - 컬렉션 기반의 api를 제공한다.
    - 맵리듀스는 메인, 매퍼, 리듀스 클래스 세가지를 만들어야 하지만, 스파크는 간단한 코드로 해결 가능하다.
    - 스칼라, 자바, 파이썬, r을 지원한다.
    - 프로그램 문제를 테스트하기 위해 쉘을 사용해서 컴파일, 배포를 반복하지 않아도 되며, 전체데이터를 처리하는 작업도 repl에서 해결할 수 있다.
    - 일괄처리 작업이나 데이터 마이닝같은 온라인 분석처리에 유용하다.
  - 단점
    - 단일노드로 충분한 앱에서는 분산 아키텍처로 인해 성능이 오히려 떨어지는 경우도 있다.
  - 컴포넌트
    - 스파크 코어
      - 스파크 잡과 다른 스파크 컴포넌트에 필요한 기본 기능을 제공한다.
      - 분산데이터 컬렉션을 추상화한 객체인 RDD(Resilent Distributed Dataset)로 다양한 연산 및 변환 메서드를 제공한다.
      - 스파크 코어는 다양한 파일시스템에 접근이 가능핟.
      - 공유변수, 누적변수를 사용해 컴퓨팅 노드간 정보를 공유한다.
      - 네트워킹, 보안, 스케쥴링, 데이터 셔플링 등 기능을 제공한다.
    - 스파크 SQL
      - 하이브 sql이 지원하는 sql을 사용해 대규모 분산 정형데이터를 다룰 수 있다.
      - json, parquet, rdb테이블, 하이브테이블 등을 읽고 쓸 수 있다.
      - dataframe과 dataset에 적용된 연산을 일정 시점에 rdd연산으로 변환해 일반 스파크 잡으로 실행한다.
    - 스파크 스트리밍
      - 실시간 스트리밍 데이터를 처리하는 프레임워크이다.
      - hdf, 카프카, 플럼, 트위터 제로mq와 더불어 커스텀 리소스도 사용할 수 있다.
      - 다른 스파크 컴포넌트와 함께 사용할 수 있다.
    - 스파크 MLlib
      - 머신러닝 알고리즘 라이브러리이다.
    - 스파크 그래프X
      <img src="http://www.bogotobogo.com/Hadoop/images/Ecosystem/Hadoop_Ecosystem3.png" width="500">
- hadoop
  - 병렬처리가 가능하고, 부분적으로 장애가 발생한 경우 전체 시스템은 동작할 수 있는 장애내성을 갖는 시스템으로 만들 수 있다.
  - 맵리듀스의 핵심은 최소한의 api만 노출해 대규모 분산 시스템을 다루는 복잡한 작업을 감춘다.
  - 병렬처리를 프로그래밍적 방법으로 지원하는 점이다.
  - 다루는 데이터가 크기때문에 데이터를 가져와서 처리하는 것이 아니라, 데이터가 저장된 곳으로 프로그램을 전송한다.
  - 이 점이 기존 dw, rdbms와 맵리듀스의 가장 큰 차이점이다.
  - 동작원리
    - job을 잘게 분할하고 cluster의 모든 node로 mapping한다.
    - 각 node는 job을 처리한 중간결과를 생성한다.
    - 분할된 중간결과를 reduce해서 최종결과를 낸다.
  - 한계
    - 맵리듀스 job의 결과를 다른 job에서 사용하려면 이 결과를 hdfs에 저장해야 한다. 그래서 이전 job의 결과가 다음 job의 입력이 되는 반복 알고리즘에는 본질적으로 알맞지 않다.
    - 하둡은 low-level 프레임워크이다 보니 데이터를 조작하는 high-level 프레임워크나 도구가 많아 환경이 복잡하다.
