# 오늘 배운 것을 정리하는 공간

## 03.12.2019

- sql
	- `WHERE col_name BETWEEN col_date AND col_date_2`: 날짜 필터링 기능
	- `WHERE col_name IN (col_1, col_2, col_3)`: 한 컬럼에서 여러 키워드 검색 기능

- puppeteer
	- window.alert 강제로 끄기
		```js
		const page = await browser.newPage();  
	  
		page.on('dialog', async dialog => {  
		 console.log(`dialog message:' ${dialog.message()}`);  
		 await dialog.dismiss();  
		});
	```

## 06.12.2019

- sqs
	- Queue Attributes
		- Default Visibility Timeout: 특정 component에 전달된 뒤, 자동으로 삭제되지 않는다. 그래서 다른 component에서 중복된 msg를 전달받을 수 있는 문제가 발생하기 떄문에, 한번 전달된 msg는 timeout에 설정된 일정시간동안은 다시 전달되지 않도록 한다. 이러한 상태를 inflight라고 한다. (기본값 30초)
		- Message Retention Period: msg의 생명주기이다. (기본값 4일)
		- Maximum Message Size: msg의 최대크기이다. 비용과 관련된다. (기본값 256kb)
		- Delivery Delay: 새로운 msg가 전달되는 초기 지연시간이다.
		- Receive Message Wait Time: `receiveMessage`에서 long polling을 활성화할 수 있다.
			- Long Polling: `receiveMessage`가 호출되었을때, msg가 없으면 일정시간동안 msg가 도착할때까지 기다린 후, 새로운 msg가 도착하면 바로 msg를 return한다. msg가 없을때 empty response에 대한 비용을 절약할 수 있다. (기본값 Short Polling)
		- Content-Based Deduplication:  
	- Dead Letter Queue Settings: msg가 성공적으로 처리되지 못했을시 msg를 따로 처리할 수 있도록 도와준다. 
		- Use Redrive Policy
		- Dead Letter Queue
		- Maximum Receives
	- Server-Side Encrpytion (SSE) Settings
		- Use SSE
		- AWS KMS Customer Master Key (CMK): (기본값 aws/sqs)
		- Data Key Reuse Period: (기본값 5분)
	- msg: 반환되는 msg의 내용
		- msg body
		- msg body의 md5 digest
		- msg 전성시 사용된 MessageId
		- ReceiptHandle: msg 삭제시 identifier로 사용한다.
		- msg attributes
		- msg attributes의 md5 digest
	- sqs와 연결하기 위해 필요한 lambda role
		- sqs에게서 msg를 전달받고, 삭제할 수 있는 역할
		- lambda를 invoking 가능한 역할
		- cloud watch에 log를 생성할 수 있는 역할

- ElasticSearch
	- term
		- index: database
		- type: table
		- document: row
		- field: column
		- mapping: schema
		- sql: dsl
			- dsl(Domain Specific Language): 특정 영영을 타겟으로 하는 언어를 말한다. 
	- rest-api-request
		- `http://<host>:<port>/<index>/<type>/<action|id>`
	- 5.0 버전 이후부터는 `index` 별로 한개의 `type`만 가질 수 있다.
		> ### Multiple mapping types are not supported in indices created in 6.0
		> The ability to have multiple mapping types per index has been removed in 6.0. **New indices will be restricted to a single type.** This is the first step in the plan to remove mapping types altogether. Indices created in 5.x will continue to support multiple mapping types.

- ELK
	- ElasticSearch
		- port: 9200
		- config: 
			- `vim /etc/elasticsearch/elasticsearch.yml`
			- `network.host: <ip>`: 설정값은 모든 호스트 열어둠.  `0.0.0.0`
			- `discovery.seed_hosts: [<ip>]`: 설정값은 localhost로 됨. `["localhost", "127.0.0.1", "[::1]"]`
			- `xpack.security.enabled: false`
		- start
			- ElasticSearch가 작동중인 상태에서 실행해야한다.
			- `sudo -u elasticsearch /usr/share/elasticsearch/bin/elasticsearch`
			- `network.host`를 바꾸면 bootstrap checks failed 오류가 발생한다.
				- `discovery.seed_hosts`, `discovery.seed_providers`, `cluster.initial_master_nodes`변수를 설정해준다.
				-  `xpack.security.transport.ssl.enabled: true`혹은 `xpack.security.enabled: false`로 변경한다.
			- 혹은 service로 설정해뒀다면 `systemctl start elasticsearch.service`
		- upgrade
			- `POST /_ml/set_upgrade_mode?enabled=true`
	- LogStash
		- config
		- start
	- Kibana
		- port: 5601
		- config: `/etc/kibana/kibana.yml`
			- `server.host: <ip>`: private ip로 작성함.
		- start: `/usr/share/kibana/bin/kibana`
			- 혹은 service로 설정해뒀다면 `systemctl start kibana.service`

- ubuntu
	- `/usr/share/fonts/`: 폰트 설치 폴더
	- `dpkg -L <프로그램명>`: 프로그램 설치 여부 확인가능

- matplotlib 
	- `home/user/.local/lib/python3.6/site-packages/matplotlib/mpl-data/fonts/`: 폰트 설치 폴더
	- `home/user/.local/lib/python3.6/site-packages/matplotlib/mpl-data/matplotlibrc`: config 파일
	- `home/user/.cache/matplotlib/ fontlist-v310.json`: config 파일

- network
	- hostname
		- `127.0.0.1`: localhost
		- `192.168.*.*`/`172.16.*.*`: 
	- subnet과 supernet 차이점
	- ip주소 비트로 계산하기 === cidr 계산법

- linux
	- service등록하는 방법
		- 등록하면 무한 자동실행이 가능해진다
	- `killall sudo`
	- `ps -ef`
	- `/var/log/`: 로그 저장한 디렉토리

## 07.12.2019

- aws
	- services
		- computing
			- EC2 Container Registry: docker img를 배포한다. 
			- EC2 Container Service
				- 저장된 docker container를 실행 및 관리한다. 
				- ec2 scaling할때 docker에서 시작되어서 관리하기 좋다.
			- Elastic Beanstalk: 내부적으로 ec2 + elb와 같고 git에서 바로 배포도 가능하다.
		- storage & contents delivery
			- CloudFront
				- cdn 서비스이다.
				- 속도가 s3의 10배 정도의 빠른 속도를 가진다. 
			- EBS(Elastic Block Store)
				- ec2용 hdd이다.
				- ssd 없는 ec2 instance에는 필수라고 한다.
				- 1개의 ebs는 하나의 ec2에만 사용가능하다.
				- 하나의 ec2에는 여러개의 ebs를 갖는 것이 가능하다.
			- EFS(Elastic File System)
				- ec2의 공유 folder이다.
				- 여러대의 ec2에서 사용할 수 있다.
			- Snowball
				- 빅데이터를 물리적으로 전송하게 해준다.
			- Storage Gateway
				- iSCSI(tcp/ip를 통해) s3, s3 glacier를 다룰 수 있다.
				- linux vm img이다. 
		- database
			- DMS(Database Migration Service): server에서 rds로 지속적으로 data를 복제해서 rds로 갈아탈 수 있다.
			- Redshift
				- 싸고 빠른 dw이다.
				- sql 구문을 해석할 수 있다.
				- 분석용으로 big data도 빠르게 분석한다.
				- indexing기능이 부재하다.
		- network
			- VPC
				- server 군을 가상 subnet 관리 하에 넣을 수 있다.
				- network segment마다 방화벽, dhcp 가상 ip, nat 등을 설정할 수 있다.
			- Direct Connect
				- data center와 전용성을 끈다.
			- Route 53: dns server이다.
		- analysis
			- EMR: 
				- hadoop 전용 ec2 instance이다.
			- Data Pipeline
				- ec2에서 매일 data를 가져다가 s3에 batch해서 할 수 있다.
			- Elasticsearch Service
			- Kinesis
				- 시간당 수 tera의 data를 실시간으로 분석 가능하다.
				- json으로 던지고 ec2에서 csv로 가공후 s3에 업로드하고 redshift를 시켜 분석이 가능하다.
				- 24시간 후 data는 자연기화한다.
			- ML
				- 이항분류, 다항분류, 회귀 기능이 있다.
				- 신경망이나 deep learning 기능은 없다.
			- QuickSight
				- 비 기술자가 자신의 data를 분석하기 위한 도구이다.
				- s3와 redshift에 원시 log를 돌리면 gui에서 그래프로 볼 수 있다.
		- enterprise application
			- WorkSpaces
			- WorkMail: 다른 aws와 연동가능하고 gmail보다 저렴하다.
			- WorkDocs: 미리보기 기능은 있지만, google docs처럼 수정은 불가능하다.
		- web service
			- Mobile Hub
				- mBaaS로 다른 service를 사용할 수 있는 console이다.
				- 소셜로그인은 cognito
				- push 알림은 sns
				- site 및 contents delivery는 s3와 cloudfront
				- 사용자 data 저장은 s3
				- 분석은 mobile analytics
				- testing은 device farm
				- rest api는 lambda fn 등이 있겠다.
				- 위 정의에 따라 실제로 움직이는 sample app을 download하는 기능까지 있다.
			- Cognito: 동기화 store라는 data 저장소가 있다.
			- Device Farm: cloud로 이어진 실제 android, ios에서 app test를 할 수 있다.
			- Mobile Analytics: application에 넣어서 사용자수, 이탈율, 독자 event 등을 집계분석이 가능하다.
			- SNS
				- push 알림 service이다.
				- mail 또는 http, sms도 사용가능하다.
				- sqs와 lambda와도 연동 가능하다.  
		- iot
			- IoT
				- iot용 sdk이다
				- mqtts에 의해 보안 통신, offline 장치의 데이터 동기화 등의 역할을 한다.
		- devtools
			- CodeCommit
				- iam 역할로 관리되는 git이다.
				- web ui는 따로 없다.
			- CodeDeploy: github이나 s3에 upload하면 ec2에 자동으로 배포한다.
			- CodePipeline
				- ci도구이다.
				- git에 push하면 자동으로 build를 하고 자동 test를 시작해서 보고서를 보낸다.
		- opstools
			- CloudWatch
				- server의 사용요금과 사용량을 monitoring, graph로 그려준다.
				- sns를 통해 알림기능도 사용할 수 있다.
			- CloudFormation: 다양한 service를 일괄적으로 구축할 수 있다.
			- CloudTrail
				- aws의 작업을 기록한다.
				- 7일간 볼 수 있다.
			- Config
				- 설정변경내역을 log로 보여준다.
			- OpsWOrks
				- 작업을 자동화할 수 있다.
				- elb 및 auto scaling과는 다른방법의 scaling방법이다.
			- Service Catalog
				- cloud formation의 저장 version을 관리해준다.
				- iam 권한 없이도 사용가능하다.
			- Trusted Advisor: test를 자동화해서 비용, 성능, 보안, 가용성 및 이중화를 관리해준다.
		- securit & id
			- IAM(Identity and Access Management)
			- ACM(AWS Certificate Manager): aws 한정으로 사용할 ssl/tls 인증서를 무료로 발급해준다.
			- Directory Service: microsoft active directory가 aws에 hosting할 수 있다.
			- Inspector: ec2 보안결함을 찾아내는 자동 분석도구이다.
			- CLoudHSM: key관리에 대해 미국 정부 표준을 준수하는 hardware 기반 key storage이다.
			- KMS(Key Management Service)
				- key 관리를 해준다. 
				- cloud hsm와의 차이는 여러 지역에서 사용이 가능하지만, aws sdk를 통해 암호화 한다는 점이다.
			- WAF: 외부 access에 대한 방화벽이다.
		- application
			- AppStream
				- cloud game과 thin client system을 제공한다.
				- 내부적으로 app은 ec2에서 win2008 r2에서 시작한다.
			- CloudSearch
				- 검색서비스이다.
				- elasticsearch와 내부 engine은 같지만 cloudsearch쪽이 조금 더 편하고 성능이 낫다.
			- ELastic Transcoder: 동영상을 encoding해준다.
			- SES
				- email 송수신 server이다.
				- workmail에 던지거나 s3에 저장하거나, lambda에 던져 분석도 가능하다.
			- SNS
			- SQS
				- kinesis와 유사하지만 data를 넣는 기능만 가지고있다.
				- dropbox는 file을 저장했을때 나오는 thumbnail img에 사용한다.
				- 검색 index를 만드는데 사용도 가능하다.
		- game
			- Lumberyard
				- full source 제공의 무료 3d game engine이다.
				- open source는 아니다.
				- pc, xbox, ps, ios, andoroid를 지원하며, mac, linux도 지원예정이다.
			- GameLift: fps나 moba 등의 multiplayter의 backend를 ec2에서 띄울 수 있게 해준다.

- cloud watch
	- `Rules - Create rule`을 선택해 cronjob을 생성할 수 있다.
	<img src="https://devblog.croquis.com/img/content/2017-05-13/cloudwatch-1.png" width="500">

- network
	- token ring
		- osi model의 data link 계층에서 쓰이는 근거리 통신망 protocol이다.
		- 1980년대 ibm이 개발했다.
		- 성공적이었지만 1990년대 ethernet의 개발로 잘 쓰이지 않게 되었다. 
	- token bus
		- 동축 cable에 가상의 고리에 protocol을 구현한 network이다.
	
- algorithm
	- scheduling
		- 다중 programming을 가능하게 하는 os의 동작기법을 말한다. os는 process들에게 cpu 등의 자원배정을 적절히 함으로서 system 성능을 개선할 수 있다.
		- 종류: 장기, 중기, 단기
		- 단계
			- 1단계: 작업 scheduling이라고도 한다. 어느 작업부터 system 내의 자원들을 실제로 사용할 수 있도록 할지를 결정한다. 작업들이 system에 들어오는 것을 승인하는 것이기 때문에 승인 scheduling이라고도 한다.
			- 2단계: 어느 process로부터 cpu를 차지할 수 있게 할지를 결정한다. process들을 보류시키고 다시 활성화시키는 기법을 사용해 system에 대한 단기적인 부하를 조절한다. 그럼으로서 system을 적절히 운영할 수 있다. 
			- 3단계: cpu가 사용가능한 경우 어느 process에 배당할지를 결정한다.
		- FCFS(First Come First Served)
			- 특징
				- 먼저 온 순서대로 처리하는 방식
				- 비선점형(non premmptive) scheduling: 일단 cpu를 잡으면 cpu burst가 완료될때까지 cpu를 반환하지 않는다. 할당되었던 cpu가 반환될때만 scheduling이 이루어진다.
			- 단점
				- convoy effect가 발생한다. 소요시간이 긴 process가 먼저 도달해 효율성을 낮추는 현상이 발생한다.
		- SJF(Shortest-Job-First)
			- 특징
				- 다른 process가 먼저 도착했어도 cpu burst time이 짧은 process에게 선 할당된다.
				- 비선점형(no preemptive) scheduling
			- 단점
				- starvation이 발생한다. 
				- 효율성을 추구하는게 가장 중요하지만, 특정 process가 지나치게 차별받으면 안되는 것이다. 이 방식은 극단적으로 cpu사용이 짧은 job을 선호한다 그래서 시간이 긴 process는 거의 영원히 cpu를 할당받을 수 없다.
		- SRTF(Shortest Remaining Time First)
			- 특징
				- 새로운 process가 도착할때마다 새로운 scheduling이 이루어진다.
				- 선점형(preemptive) scheduling: 현재 수행중인 process의 남은 burst time보다 더 짧은 cpu burst time을 가지는 새로운 process가 도착하면 cpu를 뺏긴다.
			- 문제점
				- strarvation이 발생한다. 
				- 새로운 process가 도달할때마다 scheduling을 다시 하기때문에 cpu burst time을 측정할 수 없다.
		- Priority Scheduling
			- 특징
				- 우선순위가 가장 높은 process에게 cpu를 할당하는 방식이다.
				- 우선순위는 정수로 표현되고 작은 숫자가 우선순위가 높다.
				- 선점형 (preemptive) scheduling: 더 높은 우선순위의 process가 도착하면 실행중인 process를 멈추고 cpu를 선점한다.
				- 비선점형(non preemptive) scheduling: 더 높은 우선순위의 process가 도착하면 ready queue의 head에 넣는다.
			- 문제점
				- starvation이 발생한다.
				- 무기한 봉쇄(infinite blocking)이 발생한다.
				- 실행 준비는 되었으나 cpu를 사용못하는 process를 cpu가 무기한 대기하는 상태이다.
			- 해결책
				- aging: 아무리 우선순위가 낮은 process라도 오래 기다리면 우선순위를 높여주는 방법이다.
		- Round Robin
			- 특징
				- 현대적인 cpu scheduling 방식이다.
				- 각 process는 동일한 크기의 할당시간(time quantum)을 갖게된다.
				- 할당시간이 지나면 process는 선점당하고 ready queue의 제일 뒤에 가서 다시 줄을 선다.
				- 이 방식은 cpu 사용시간이 random한 process들이 섞여있을 경우에 효율적이다.
				- process의 context를 저장할 수 있기 때문이다.
			- 장점
				- 응답시간이 빨라진다. n개의 process가 ready queue에 있고 할당시간이 q인 경우,  각각 process는 q단위로 cpu시간의 1/n을 얻는다. 즉, 어떤 process도 (n-1)q timeout 이상 기다리지 않는다.
				- process가 기다리는 시간이 cpu를 사용할만큼 증가한다. 공정한 scheduling이라고 할 수 있다.
			- 주의점
				- 설정한 할당시간이 너무 커지면 fcfs방식과 같아진다. 또 너무 작아지면 scheduling algorithm 목적에는 이상적이지만 잦은 context switch로 overhead가 발생한다.
	- quicksort: 원소를 정해(pivot을 통해) 해당 원소보다 작은 수들과 큰 수들로 나눈다. 차례대로 작은 수들, pivot, 큰 수를 차곡차곡 담으면 정렬이 된다.

- sql
	- export csv
		```sql
		mysql -u work543 -p \
		--database=db_name 
		--host=host_name.ap-southeast-1.rds.amazonaws.com \
		--port=3306 \
		--batch -e "select * from batch" | \
		sed 's/\t/","/g;s/^/"/;s/$/"/;s/\n//g' > /home/ubuntu/export.csv
		```

- nodejs
	- express
		- async/await
			- test용 비동기함수
				```js
				const asyncFunction = () => {
					return new Promise(resolve => {
						setTimeout(_ => {
							resolve({ message: 'success' });
						}, 3000);
					});
				};
				```
			- 실제 router에서 cb용 익명함수 앞에 async를 붙일 수 있게 해준다. 
				```js
				app.use('/async-function', async (req, res) => {
					const result = await asyncFunction();
					res.json(result);
				});
				```
			- error handling: router는async를 붙인 cb함수 내의 err를 감지하지 못한다. 따라서 `try-catch` block을 씌워줘야한다.
				```js
				app.use('/async-function', async (req, res, next) => {
					try {
						const result = await asyncFunction();
						throw new Error('Async 사용자 정의 에러 발생');
						res.json(result);
					} catch (error) {
						next(error);
					}
				});
				```
			- refactoring: 모든 cb마다 `try-catch` block을 씌우는 것은 지저분하다. 그래서 interface인 wrapper 함수를 만든다. error handling에서 만든 async cb함수를 반환하는 간단한 함수이다. promise 관련 error가 발생한다면 `next()`를 반환한다.
				```js
				const wrapper = asyncFn => {
					return (async (req, res, next) => {
						try {
							return await asyncFn(req, res, next);
						} catch (error) {
							return next(error);
						}
					});
				};

				app.use('/async-function', wrapper(async (req, res, next) => {
					// await가 필요한 작업을 합니다.
				}))
				```

- aws 
	- lambda
		- iam에서 새로운 사용자를 추가한다.
		- `Programmatic access`를 체크한 후 권한 설정을 한다.
		- `AdministratorAccess`를 체크해 다양한 asset들을 추가 혹은 삭제할 수 있도록 선택한다.
		- 다음 페이지로 넘어가면 `Access Key ID`와 `Secret Access Key`를 알려준다.
		- serverless에 iam key키를 추가해 계정을 연결시켜준다. `serverless config credentials --provider aws --key xxx --secret xxx`
		- `serverless.yml`을 선언한다. `serverless create --template aws-nodejs --path my-path` 
			- 함수의 runtime을 template이라고 부른다.
		- parameters
			- `event`: 함수에 넘겨진 event data이다.
			- `context`: 함수의 context, running time, state 등의 중요한 정보를 담고있다.
			- `callback`: 어떤 data를 반환할 것인지를 뜻한다. callback의 첫번째 인자는 언제나 error이다.
		- 배포
			- `serverless deploy -v`로 할 수 있다.
			- `-v`: verbose log를 볼 수 있다.
		- testing
			- `serverless invoke -f fn-name -l`
			- response와 lambda fn의 현재 상태에 대한 정보, 실행시간, memory 사요량 등도 같이 반환한다.
		- offline
			- `yarn add serverless-offline` plugin을 사용하면 local환경에서 test할 수 있다.
			- `serverless.yml`에 `plugins`에 추가해준다.
		- logging
			- elasticSearch와 kibana를 사용하면 monitoring 환경을 구축할 수 있다. 
				- 일정 갯수 이상의 오류가 발생할 경우 slack이나 mail로 알림이 오도록 설정이 가능하다.
			- 연결된 다른 lambda fn과의 문제까지 자세히 위의 구성으로는 파악하기 어려워 X-Ray를 사용하면 손쉽게 확인가능하다.
			- lambda, db, s3 등에서 지연시간 등을 diagram으로 확인가능해 병목현상이 어디서 일어나는지를 쉽게 파악할 수 있다.
		- dynamodb 연결
			- sam을 사용할 경우 local환경에 docker를 통해 사용가능하다.
			- serverless를 이용한다면 plugin을 통해 구축가능하다.
		- step function 연결
			- lambda fn는 기본적으로 상태값이 없다.
			- 어떤 작업을 처리하기 위해 db에서 data를 확인하는 등의 작업이 필요하다.
			- shopping mall의 경우 data를 받아도 현재 사용자가 결제한 상태인지 장바구니에만 넣은 상태인지 확인해야하는 경우 사용할 수 있다.
			- lambda fn을 workflow 단위로 묶은 service이다.
			- post, get을 통해 주문번호를 받고, 그 주문번호와 일치하는 step fn으로 data를 넘긴다.
			- 그러면 진행중이었던 단계에 맞게 그 데이터를 처리할 lambda fn에 data를 보내준다.
			- 아래와 같은 구성을 하면 상태정보를 조회하기 위한 db에서의 병목현상을 줄일 수 있다.
			<img src="https://miro.medium.com/max/1500/1*d-dcGlMdZrfS0gOaJ5eI2w.jpeg" width="500">
		- 긴 작업 처리방법
			- 10분~1시간
				- db backup, 영상 encoding 등 computing power가 많이 필요한 경우에는 ecs fargate를 사용하면 경제적으로 사용가능하다.
				- 사용자가 만든 docker img를 별도의 ec2 instance나 기타설정 없이 실행하고, 실행된 시간만큼 금액을 지불한다.
				- 동영상 구간별 thumbnail 추출같은 작업에서 효율적으로 사용가능하다.
			- 수시간
				- ecs fargate는 서울에서는 사용할 수 없는데다 ec2보다 비싸다.
				- 이정도의 장시간 작업은 ecs, ec2를 사용하는 것이 더 경제적이다.

- nodejs 
	- pm2
		- start
			- `pm2 start app.js -- -a 23`: -a 23이라는 인수를 전달한다.
			- `pm2 start app.js --n name`: name이라는 process이름을 지정한다.
				- `--name`은 `-n`과 동일하다
			- `pm2 start app.js --node-args="--debug=7001"`: --node-args를 통해 v8 engine에 opt값을 전달한다.
			- `pm2 start app.js -i max`: cpu를 최대치로 할당한다. cluster전용이다.
			- `pm2 start app.js --log-date-format "YYYY-MM-DD HH:mm Z"`: log의 시간data format을 지정한다.
			- `pm2 start app.js -e err.log -o out.log`: output log와 err log의 위치를 지정한다.
			- `pm2 --run-as-user user start app.js`: pm2를 실행하는 사용자는 user로 설정한다.
		- rc file: 위의 opt를 json으로 관리할 수 있다.
			```json
			{
				"apps" : [{ 
					"name"        : "worker",
					"script"      : "./worker.js",
					"watch"       : true,
					"ignore_watch" : ["node_modules", "client/img"],
					"watch_options": {
						"followSymlinks": false
					},
					"env": {
						"NODE_ENV": "development"
					},
					"env_production" : {
						"NODE_ENV": "production"
					}
				},{
					"name"       : "api-app",
					"script"     : "./api.js",
					"instances"  : 4,
					"exec_mode"  : "cluster"
				}]
			}
			```
			- opts: `pm2 start config.json`으로 rc를 불러온다.
				- `listen_timeout`: app의 응답이 없을경우 재시작할 시간을 설정한다.
				- `min_update`: 일정시간 이후 재시작을 원할경우 설정한다.
				- `max_restart`: 재시작 최대횟수
				- `restart_delay`: 재시작 delay
				- `cron_restart`: cron을 통해 재시작
		- process management
			- `pm2 stop all`: 모든 process를 멈춘다.
			- `pm2 restart all`: 모든 process를 재시작한다.
			- `pm2 reload all`: 모든 process의 downtime을 0으로 설정후 reload한다.
			- `pm2 delete all`: 모든 process를 삭제한다.
			- `pm2 ping`: pm2가 사용가능한지 ping을 확인한다.
			- `pm2 updatePM`
			- `pm2 reset <process>`: reset후 metadata를 reload한다.
		- log management
			- `pm2 logs`: 모든 log를 출력한다.
			- `pm2 ilogs`: 자세한 log를 출력한다.
			- `pm2 flush`: 모든 log를 비운다.
			- `pm2 reloadLogs`: log를 다시 불러온다.
		- deploy
			- 배포에 관한 내용도 conf file에서 가능하다. 기존의 json에서 `apps`이외에 `deploy`에 상세설정을 할 수 있다.
				```json
				{
					"apps" : [{
							"name" : "HTTP-API",
							"script" : "http.js"
					}],
					"deploy" : {
						"production" : {
							"user" : "ubuntu",
							"host" : ["192.168.0.13"],
							"ref"  : "origin/master",
							"repo" : "git@github.com:Username/repository.git",
							"path" : "/var/www/my-repository",
							"post-deploy" : "npm install; grunt dist"
							},
					}
				}
				```
			- 위와 같이 설정하면 server에 deploy 명령을 할때마다 git repo에서 자동으로 가져와 package를 설치후, node process를 실행한다.
			- `pm2 deploy production setup`: git에서 code를 받아 setting한다.
			- `pm2 deploy production update`: 이미 setup한 경우 update를 통해 새 version을 받는다.
			- `pm2 deploy production rever 1`: 이전 version으로 돌리는 명령어이다. setup을 통해 배포한 경우 folder를 열어보면 전에 받았던 node server의 img를 가지고 있어 바로 복구가능하다.
			- `pm2 deploy production exec "pm2 reload all"`: deploy한 후의 추가적인 명령어를 parameter로 줄 수 있다.
			- post deploy 이외의 pre setup, post setup, post deploy local 등의 event parameter를 줄 수 있다. 

- elasticsearch

## 08.12.2019

- linux
	- `systemctl enable --now <service_name>`: system reboot시 자동 재실행되도록 `enable --now`옵션을 붙여준다.