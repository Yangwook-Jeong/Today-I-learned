## 04.01.2020

- ANN(Aritifical Neural Network) algorithm
  - DFN
    - Deep Feedforward Network
    - 가장 기본적으로 이용하는 인공신경망이다.
    - 입력, 은닉, 출력 계층으로 이루어져 있고, 보통 2개 이상의 은닉 계층을 이용한다.
    - DFN에서 입력데이터는 입력, 은닉, 출력 계층의 순서로 전파된다.
    - 현재 입력된 데이터가 계층을 거치면서 예측값으로 변환된 뒤 현재 데이터에 대한 정보는 완저닣 사라진다.
    - 입력되었던 데이터의 정보가 저장되지 않기때문에 입력 순서가 존재하는 시계열 데이터를 처리하는데는 문제가 있다.
    <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbHm6CY%2Fbtqz74BNVGM%2FTLopKuVKfwVlgKKkT7MC81%2Fimg.png" width="250">
  - RNN
    - Recurrent Neural Network
    - DFN의 단점을 극복할 수 있다.
    - 시계열 데이터와 같이 시간 연속성이 있는 데이터를 처리하기 위해 고안되었다.
    - 시계열 데이터나 문자열은 일반적으로 앞에 입력된 데이터에 의해 뒤에 입력된 데이터에 대한 예측이 영향을 받는다.
    - 각 뉴런에 순환 연결을 추가해 이전 시간에 입력된 데이터에 대한 은닉 계층의 출력을 현재 시간의 데이터를 예측할 때 다시 은닉 계층 뉴런에 입력한다.
    - 이전 시간에 입력된 데이터를 같이 고려해 현재 시간에 입력된 데이터를 가지고 예측할 수 있다.
    - 단순한 RNN은 역전파 알고리즘을 기반으로해 오랜 시간에 걸쳐 추세를 나타내는 데이터를 학습할 때 gradient가 감소하거나 증가하는 문제가 생길 수 있다.

      <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fd6XtY0%2Fbtqz8wrsL4S%2FJZRZeRbNbAnLOpKX5k1l80%2Fimg.png" width="250">
  - LSTM
    - Long Short-Term Memory
    - forget, input, output gate라는 새로운 요소를 은닉 계층의 각 뉴런에 추가했다.
      - forget gate: 과거의 정보를 어느정도 기억할지 결정한다. 과거의 데이터와 현재 데이터를 받아 sigmoid를 취한 뒤 그 값을 과거의 정보에 곱한다. sigmoid의 출력이 0인 경우는 과거의 데이터를 완전히 잊고, 1일 경우는 과거의 데이터를 온전히 보존한다.
      - input gate: 현재의 데이터를 기억하기 위해 만들어졌다. 과거의 데이터와 현재 데이터를 입력받아 sigmoid와 tanh 함수를 기반으로 현재 정보에 대한 보존량을 결정한다.
      - output gate: 과거의 데이터와 현재 데이터를 이용해 뉴런의 출력을 결정한다.
    <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FdRbBGM%2Fbtqz8of6Jxg%2FDf4GLffr2g7AhC7oiEYLZ1%2Fimg.png" width="250">
  - Autoencoder
    - 데이터와 그에 대한 예측값 모두를 이용해 입력 데이터에 대한 예측을 수행하는 것을 지도학습이라고 한다.
    - 앞선 알고리즘은 모두 지도학습에 해당하지만, 이 알고리즘은 비지도 학습을 기반으로 학습한다.
    - 따라서 autoencoder의 학습에서는 예측값이 필요가 없다.
    - 입력, 은닉, 출력 계층을 거쳐 입력 데이터가 그대로 다시 출력되도록 동작한다.
    - 출력 계층의 출력이 아니라, 은닉 계층의 출력을 이용하는 것에 목적이 있다.
    - 아래와 같은 의미와 활용을 한다.
      - data compression: 은닉 계층의 뉴런 수를 입력, 출력 계층 뉴런 수보다 적게 설정하기때문에 은닉 계층의 출력은 입력 데이터에 대한 압축 데이터로 볼 수 있다.
      - latent representation: 은닉 계층은 그 자체로 입력 데이터를 잘 표현하기 위한 새로운 공간을 형성한다. 그래서 은닉 계층의 출력은 입력 데이터에 대한 latent representation으로 활용할 수 있다.
    <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fdl0qQI%2Fbtqz8wym3WJ%2FiKppnuXN0ubrO9duPcNoiK%2Fimg.png" width="250">
  - VAE
    - Variational Autoencoder
    - 기존 autoencoder에 확률 개념을 추가한 모델이다.
    - autoencoder에서는 입력 데이터를 그대로 복원하기 위해 학습을 진행했다면, VAE에서는 입력 데이터의 확률 분포를 근사하기 위한 학습을 진행한다.
  
    <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbfSSf2%2Fbtqz8ogbVy1%2F4SljbRbchDNrDWf9vsyx91%2Fimg.png" width="250">
  - CNN
    - Convolutional Neural Network
    - 생명체의 시각처리 방식을 모방하기 위해 나선형의 연산을 인공신경망에 도입해 이미지 처리 분야에 사용해왔다.
    - 입력, 출력 부분에서 뉴런들이 느슨하게 연결되어있다. DFN, RNN에 비해 학습해야하는 가중치가 적으며, 이 덕에 학습, 예측이 빠르다는 장점이 있다.
    - 이미지, 시계열 데이터에서도 CNN을 활용하는 연구가 진행중이다.
    
    <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FbkAuba%2Fbtqz8ZmFQHO%2FxcqkfX6cCu0flJq8RKo7Ak%2Fimg.png" width="500">
  - DRN
    - Deep Residual Network
    - 인공신경망에 계층이 많아질수록 성능이 증가하냐는 질문에서 시작했다.
    - 계층이 많아질수록 성능이 향상되지 않고, 하락하는 문제가 발생했다.
    - 이 문제를 해결하기 위해 skip connection을 통해 일반적인 인공신경망에서 데이터가 계층의 순서에 따라 순차적으로 전파되는 것에 반해, DRN에서는 다다음 계층으로 직접 전달하는 것을 확인할 수 있다.
    - DRN은 CNN과 결합해 사용하는데, 이러한 신경망을 ResNet이라고 한다.
    - 이미지 처리분야에서 뛰어난 성능을 보여주고 있다.
    
    <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FBtZLn%2FbtqAcp498GJ%2FgaSSlKI0BjALPkkX0hcmkK%2Fimg.png" width="500">
  - GAN
    - Generative Adversarial Network
    - VAE같은 generative model이다. 
    - 이미지를 생성하는데 뛰어난 성능을 보여준다.
    - 데이터셋에 없는 사람의 얼굴을 스스로 생성하건, 화가의 화풍을 모방해 새로운 그림을 그리는 결과물을 보여준다.
    - 기존의 인공신경망과는 다르게 GAN은 두 개의 인공신경망이 서로 경쟁하며 학습한다.
    - 이러한 두 개의 신경망을 generator, discriminator라고 하며, 각각 다른 목적을 가지고 학습한다.
    - generator는 주어진 데이터를 보고 최대한 데이터와 비슷한 가짜 데이터를 생성한다.
    - discriminator는 진짜 데이터와 generator가 만든 가짜 데이터가 입력되었을 때, 어떤 것이 진짜 데이터인지를 판별한다.
    - generator는 discriminator를 속이기 위해 위품을 만들고, disciriminator는 위품을 구별한다. 이 과정을 반복하면 discriminator는 점점 진짜와 가짜를 잘 구분하게 되고, generator는 더욱 진짜같은 가짜를 만들게 된다. 
    <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FxAcFp%2FbtqAccd821v%2FkBVm0JempLqKxP7dMkB1Kk%2Fimg.png" width="500">
  - GCN
    - Graph Convolutional Network
    - 기존 인경신경망은 기본적으로 입력 데이터가 euclidean space에 존재함을 가정하고 있다.
    - 입력 데이터는 반드시 벡터, 행렬의 형태로 표현할 수 있어야 했다.
    - 하지만 SNS, RDBMS, 분자구조와 같은 데이터는 벡터, 행렬로 표현이 불가능한 그래프의 형태로 나타나기때문에 그래프 데이터 처리를 위한 신경망이 바로 이것이다.

    <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FckSWPp%2FbtqAcbmi8yT%2FruOK2cWNQjbV15azaH8Mvk%2Fimg.png" width="500">
  - SNN
    - Spiking Nerual Network
    - 기존 인공신경망보다 더욱 세밀하게 생물학적 뉴런을 묘사하기 위해 제안되었다.
    - 각 뉴런은 완전 연결된 것이 아니라, 실제 생물의 뇌처럼 연관된 동작을 하는 뉴런들끼리만 연결되어있다.
    - 뉴런이 생물학적 뉴런의 전기 신호처럼 spike의 발생여부를 나타내는 0, 1의 값을 출력한다.
    - 뉴런 자체에서 시간에 따라 출력값이 변하기도 한다.
    - 이는 신경망 자체의 복잡성 증가 없이도 시간에 종속적인 데이터에 대한 처리가 가능함을 의미한다.

    <img src="https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcjazKl%2FbtqAcMGm1rF%2FPCq1onOuIvMaaIIHYSVtjK%2Fimg.png" width="500">

## 05.01.2020

- CP(Concurrent Programming)
  - 경쟁상태(race condition)
    - 둘 이상의 입력이나 조작의 타이밍이나 순서가 결과값에 영향을 줄 수 있는 상태를 말한다.
    - 예쌍과 다르게 작동하면 정상적인 결과가 나오지 않아 위험할 수 있다.
  - 임계구역(critical section)
    - 공유변수 영역이라고도 부른다.
    - 병렬컴퓨팅에서 둘 이상의 쓰레드가 동시에 접근해서는 안되는 공유자원을 접근하는 코드의 일부를 말한다.
    - 임계구역은 지정된 시간이 지난 후에 종료된다.
    - 어떤 쓰레드가 임계구역에 들어가고자 한다면 지정된 시간만큼 대기해야 한다.
    - 쓰레드가 공유자원의 배타적인 사용을 보장받기 위해서 임계구역에 출입할 때는 세마포어같은 동기화 매커니즘을 사용한다.
    
    <img src="https://www.charlezz.com/wordpress/wp-content/uploads/2020/12/www.charlezz.com-img1.daumcdn.png" width="500">
  - 세마포어(semaphore)
    - 2개의 원자적 함수로 조작되는 정수 변수이다.
    - 멀티 프로그래밍 환경에서 공유자원에 접근을 제한하는 방법으로 사용한다.
    - 세마포어를 이용하면 각각 `10000`번 증가하는 함수와 감소하는 함수를 동작할 시에 경쟁상태가 발생하지 않고 `0`을 반환할 수 있다.
    
    <img src="https://www.charlezz.com/wordpress/wp-content/uploads/2020/12/www.charlezz.com-img1.daumcdn-1.png" width="500">
  - 교착상태(deadlock)
    - 2개 이상의 작업이 서로 상대방의 작업이 끝나기만을 기다리고 있기 때문에 아무것도 완료하지 못하는 상태를 말한다.